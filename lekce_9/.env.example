# MCP Server Configuration
MCP_SERVER_URL=http://localhost:8002/mcp
MCP_SERVER_NAME=mcp-server
MCP_TRANSPORT=streamable_http  # streamable_http | sse | stdio

# LLM Configuration
LLM_PROVIDER=ollama  # ollama | openai
LLM_MODEL=llama3.1:8b
LLM_TEMPERATURE=0

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# System Prompt (optional - has default)
SYSTEM_PROMPT=You are a helpful AI assistant with access to various tools.
